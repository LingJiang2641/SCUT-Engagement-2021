{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\" \n",
    "#实现多输出\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.mlab as mlab  \n",
    "import matplotlib.pyplot as plt  \n",
    "import jieba\n",
    "import textdistance\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>PRIMARY_NAME</th>\n",
       "      <th>ALT_NAME</th>\n",
       "      <th>State</th>\n",
       "      <th>Cosine Similarity</th>\n",
       "      <th>Levenshtein Distance</th>\n",
       "      <th>Jaro-Winkler Distance</th>\n",
       "      <th>Jaccard Index</th>\n",
       "      <th>Monge Elkan</th>\n",
       "      <th>MRA</th>\n",
       "      <th>Longest Common Substring</th>\n",
       "      <th>Longest Common Subsequence</th>\n",
       "      <th>In String Search</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>gazprombank upravlenie aktivami</td>\n",
       "      <td>gazprombank asset management zao</td>\n",
       "      <td>match</td>\n",
       "      <td>0.666751</td>\n",
       "      <td>17</td>\n",
       "      <td>0.847686</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.024974</td>\n",
       "      <td>4</td>\n",
       "      <td>0.387097</td>\n",
       "      <td>0.580645</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>gazprombank upravlenie aktivami</td>\n",
       "      <td>closed joint-stock company gazprombank-upravle...</td>\n",
       "      <td>match</td>\n",
       "      <td>0.731083</td>\n",
       "      <td>28</td>\n",
       "      <td>0.683537</td>\n",
       "      <td>0.534483</td>\n",
       "      <td>0.032258</td>\n",
       "      <td>3</td>\n",
       "      <td>0.612903</td>\n",
       "      <td>0.967742</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>united instrument manufacturing corporation</td>\n",
       "      <td>jsc-united-instrument-manufacturing-corporation</td>\n",
       "      <td>match</td>\n",
       "      <td>0.889768</td>\n",
       "      <td>7</td>\n",
       "      <td>0.802099</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.021633</td>\n",
       "      <td>3</td>\n",
       "      <td>0.302326</td>\n",
       "      <td>0.930233</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>gaz-oil ooo</td>\n",
       "      <td>gaz-oil</td>\n",
       "      <td>match</td>\n",
       "      <td>0.797724</td>\n",
       "      <td>4</td>\n",
       "      <td>0.927273</td>\n",
       "      <td>0.636364</td>\n",
       "      <td>0.082645</td>\n",
       "      <td>4</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>ken wong</td>\n",
       "      <td>ken wong kaw</td>\n",
       "      <td>match</td>\n",
       "      <td>0.816497</td>\n",
       "      <td>4</td>\n",
       "      <td>0.933333</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>3</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                 PRIMARY_NAME  \\\n",
       "0           0              gazprombank upravlenie aktivami   \n",
       "1           1              gazprombank upravlenie aktivami   \n",
       "2           2  united instrument manufacturing corporation   \n",
       "3           3                                  gaz-oil ooo   \n",
       "4           4                                     ken wong   \n",
       "\n",
       "                                            ALT_NAME  State  \\\n",
       "0                   gazprombank asset management zao  match   \n",
       "1  closed joint-stock company gazprombank-upravle...  match   \n",
       "2    jsc-united-instrument-manufacturing-corporation  match   \n",
       "3                                            gaz-oil  match   \n",
       "4                                       ken wong kaw  match   \n",
       "\n",
       "   Cosine Similarity  Levenshtein Distance  Jaro-Winkler Distance  \\\n",
       "0           0.666751                    17               0.847686   \n",
       "1           0.731083                    28               0.683537   \n",
       "2           0.889768                     7               0.802099   \n",
       "3           0.797724                     4               0.927273   \n",
       "4           0.816497                     4               0.933333   \n",
       "\n",
       "   Jaccard Index  Monge Elkan  MRA  Longest Common Substring  \\\n",
       "0       0.500000     0.024974    4                  0.387097   \n",
       "1       0.534483     0.032258    3                  0.612903   \n",
       "2       0.800000     0.021633    3                  0.302326   \n",
       "3       0.636364     0.082645    4                  1.000000   \n",
       "4       0.666667     0.125000    3                  1.000000   \n",
       "\n",
       "   Longest Common Subsequence  In String Search  \n",
       "0                    0.580645                 0  \n",
       "1                    0.967742                 0  \n",
       "2                    0.930233                 0  \n",
       "3                    1.000000                 1  \n",
       "4                    1.000000                 1  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_excel('C:/Users/DELL/Desktop/new/cleaned_new.xlsx')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#随机森林"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import RandomizedSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = data.iloc[:,4:]\n",
    "y = data.iloc[:,3]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f(y):\n",
    "    if y=='match':\n",
    "        return 1\n",
    "    else: \n",
    "        return 0\n",
    "y = [f(y) for y in y.values]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train,x_test,y_train,y_test = train_test_split(x,y,test_size=0.3,random_state=0)  #构建训练集以及测试集用于模型的构建"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Cosine Similarity</th>\n",
       "      <th>Levenshtein Distance</th>\n",
       "      <th>Jaro-Winkler Distance</th>\n",
       "      <th>Jaccard Index</th>\n",
       "      <th>Monge Elkan</th>\n",
       "      <th>MRA</th>\n",
       "      <th>Longest Common Substring</th>\n",
       "      <th>Longest Common Subsequence</th>\n",
       "      <th>In String Search</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>27388</th>\n",
       "      <td>0.555937</td>\n",
       "      <td>23</td>\n",
       "      <td>0.560440</td>\n",
       "      <td>0.384615</td>\n",
       "      <td>0.029337</td>\n",
       "      <td>1</td>\n",
       "      <td>0.076923</td>\n",
       "      <td>0.346154</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15514</th>\n",
       "      <td>0.611775</td>\n",
       "      <td>24</td>\n",
       "      <td>0.646491</td>\n",
       "      <td>0.410256</td>\n",
       "      <td>0.044321</td>\n",
       "      <td>1</td>\n",
       "      <td>0.263158</td>\n",
       "      <td>0.631579</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5834</th>\n",
       "      <td>0.503220</td>\n",
       "      <td>35</td>\n",
       "      <td>0.582072</td>\n",
       "      <td>0.297872</td>\n",
       "      <td>0.043210</td>\n",
       "      <td>0</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16160</th>\n",
       "      <td>0.578947</td>\n",
       "      <td>17</td>\n",
       "      <td>0.436090</td>\n",
       "      <td>0.407407</td>\n",
       "      <td>0.041551</td>\n",
       "      <td>0</td>\n",
       "      <td>0.052632</td>\n",
       "      <td>0.315789</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28324</th>\n",
       "      <td>0.360041</td>\n",
       "      <td>19</td>\n",
       "      <td>0.526455</td>\n",
       "      <td>0.218750</td>\n",
       "      <td>0.040123</td>\n",
       "      <td>0</td>\n",
       "      <td>0.055556</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20757</th>\n",
       "      <td>0.849706</td>\n",
       "      <td>6</td>\n",
       "      <td>0.920947</td>\n",
       "      <td>0.730769</td>\n",
       "      <td>0.050000</td>\n",
       "      <td>3</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.950000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32103</th>\n",
       "      <td>0.417029</td>\n",
       "      <td>19</td>\n",
       "      <td>0.372786</td>\n",
       "      <td>0.230769</td>\n",
       "      <td>0.074074</td>\n",
       "      <td>0</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30403</th>\n",
       "      <td>0.587137</td>\n",
       "      <td>43</td>\n",
       "      <td>0.568478</td>\n",
       "      <td>0.385965</td>\n",
       "      <td>0.014053</td>\n",
       "      <td>0</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.407407</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21243</th>\n",
       "      <td>0.376309</td>\n",
       "      <td>38</td>\n",
       "      <td>0.421523</td>\n",
       "      <td>0.187500</td>\n",
       "      <td>0.008264</td>\n",
       "      <td>1</td>\n",
       "      <td>0.153846</td>\n",
       "      <td>0.461538</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2732</th>\n",
       "      <td>0.511478</td>\n",
       "      <td>32</td>\n",
       "      <td>0.524299</td>\n",
       "      <td>0.309524</td>\n",
       "      <td>0.048443</td>\n",
       "      <td>0</td>\n",
       "      <td>0.176471</td>\n",
       "      <td>0.411765</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>29303 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Cosine Similarity  Levenshtein Distance  Jaro-Winkler Distance  \\\n",
       "27388           0.555937                    23               0.560440   \n",
       "15514           0.611775                    24               0.646491   \n",
       "5834            0.503220                    35               0.582072   \n",
       "16160           0.578947                    17               0.436090   \n",
       "28324           0.360041                    19               0.526455   \n",
       "...                  ...                   ...                    ...   \n",
       "20757           0.849706                     6               0.920947   \n",
       "32103           0.417029                    19               0.372786   \n",
       "30403           0.587137                    43               0.568478   \n",
       "21243           0.376309                    38               0.421523   \n",
       "2732            0.511478                    32               0.524299   \n",
       "\n",
       "       Jaccard Index  Monge Elkan  MRA  Longest Common Substring  \\\n",
       "27388       0.384615     0.029337    1                  0.076923   \n",
       "15514       0.410256     0.044321    1                  0.263158   \n",
       "5834        0.297872     0.043210    0                  0.111111   \n",
       "16160       0.407407     0.041551    0                  0.052632   \n",
       "28324       0.218750     0.040123    0                  0.055556   \n",
       "...              ...          ...  ...                       ...   \n",
       "20757       0.730769     0.050000    3                  0.500000   \n",
       "32103       0.230769     0.074074    0                  0.111111   \n",
       "30403       0.385965     0.014053    0                  0.111111   \n",
       "21243       0.187500     0.008264    1                  0.153846   \n",
       "2732        0.309524     0.048443    0                  0.176471   \n",
       "\n",
       "       Longest Common Subsequence  In String Search  \n",
       "27388                    0.346154                 0  \n",
       "15514                    0.631579                 0  \n",
       "5834                     0.500000                 0  \n",
       "16160                    0.315789                 0  \n",
       "28324                    0.333333                 0  \n",
       "...                           ...               ...  \n",
       "20757                    0.950000                 0  \n",
       "32103                    0.444444                 0  \n",
       "30403                    0.407407                 0  \n",
       "21243                    0.461538                 0  \n",
       "2732                     0.411765                 0  \n",
       "\n",
       "[29303 rows x 9 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " ...]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 10 candidates, totalling 30 fits\n",
      "[CV] n_estimators=1600, min_samples_split=4, min_samples_leaf=2, max_features=sqrt, max_depth=30, bootstrap=True \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  n_estimators=1600, min_samples_split=4, min_samples_leaf=2, max_features=sqrt, max_depth=30, bootstrap=True, total= 1.2min\n",
      "[CV] n_estimators=1600, min_samples_split=4, min_samples_leaf=2, max_features=sqrt, max_depth=30, bootstrap=True \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:  1.2min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  n_estimators=1600, min_samples_split=4, min_samples_leaf=2, max_features=sqrt, max_depth=30, bootstrap=True, total= 1.3min\n",
      "[CV] n_estimators=1600, min_samples_split=4, min_samples_leaf=2, max_features=sqrt, max_depth=30, bootstrap=True \n",
      "[CV]  n_estimators=1600, min_samples_split=4, min_samples_leaf=2, max_features=sqrt, max_depth=30, bootstrap=True, total= 1.3min\n",
      "[CV] n_estimators=1000, min_samples_split=4, min_samples_leaf=2, max_features=sqrt, max_depth=80, bootstrap=False \n",
      "[CV]  n_estimators=1000, min_samples_split=4, min_samples_leaf=2, max_features=sqrt, max_depth=80, bootstrap=False, total= 1.3min\n",
      "[CV] n_estimators=1000, min_samples_split=4, min_samples_leaf=2, max_features=sqrt, max_depth=80, bootstrap=False \n",
      "[CV]  n_estimators=1000, min_samples_split=4, min_samples_leaf=2, max_features=sqrt, max_depth=80, bootstrap=False, total= 1.1min\n",
      "[CV] n_estimators=1000, min_samples_split=4, min_samples_leaf=2, max_features=sqrt, max_depth=80, bootstrap=False \n",
      "[CV]  n_estimators=1000, min_samples_split=4, min_samples_leaf=2, max_features=sqrt, max_depth=80, bootstrap=False, total= 1.4min\n",
      "[CV] n_estimators=800, min_samples_split=4, min_samples_leaf=2, max_features=auto, max_depth=80, bootstrap=False \n",
      "[CV]  n_estimators=800, min_samples_split=4, min_samples_leaf=2, max_features=auto, max_depth=80, bootstrap=False, total= 1.2min\n",
      "[CV] n_estimators=800, min_samples_split=4, min_samples_leaf=2, max_features=auto, max_depth=80, bootstrap=False \n",
      "[CV]  n_estimators=800, min_samples_split=4, min_samples_leaf=2, max_features=auto, max_depth=80, bootstrap=False, total= 1.0min\n",
      "[CV] n_estimators=800, min_samples_split=4, min_samples_leaf=2, max_features=auto, max_depth=80, bootstrap=False \n",
      "[CV]  n_estimators=800, min_samples_split=4, min_samples_leaf=2, max_features=auto, max_depth=80, bootstrap=False, total= 1.1min\n",
      "[CV] n_estimators=900, min_samples_split=1, min_samples_leaf=2, max_features=auto, max_depth=80, bootstrap=False \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Anaconda\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\Anaconda\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"E:\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"E:\\Anaconda\\lib\\site-packages\\joblib\\parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"E:\\Anaconda\\lib\\site-packages\\joblib\\parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"E:\\Anaconda\\lib\\site-packages\\joblib\\parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"E:\\Anaconda\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"E:\\Anaconda\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"E:\\Anaconda\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"E:\\Anaconda\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"E:\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 170, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=sample_weight, check_input=False)\n",
      "  File \"E:\\Anaconda\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"E:\\Anaconda\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  n_estimators=900, min_samples_split=1, min_samples_leaf=2, max_features=auto, max_depth=80, bootstrap=False, total=   0.6s\n",
      "[CV] n_estimators=900, min_samples_split=1, min_samples_leaf=2, max_features=auto, max_depth=80, bootstrap=False \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Anaconda\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\Anaconda\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"E:\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"E:\\Anaconda\\lib\\site-packages\\joblib\\parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"E:\\Anaconda\\lib\\site-packages\\joblib\\parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"E:\\Anaconda\\lib\\site-packages\\joblib\\parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"E:\\Anaconda\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"E:\\Anaconda\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"E:\\Anaconda\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"E:\\Anaconda\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"E:\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 170, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=sample_weight, check_input=False)\n",
      "  File \"E:\\Anaconda\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"E:\\Anaconda\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  n_estimators=900, min_samples_split=1, min_samples_leaf=2, max_features=auto, max_depth=80, bootstrap=False, total=   0.7s\n",
      "[CV] n_estimators=900, min_samples_split=1, min_samples_leaf=2, max_features=auto, max_depth=80, bootstrap=False \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Anaconda\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\Anaconda\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"E:\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"E:\\Anaconda\\lib\\site-packages\\joblib\\parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"E:\\Anaconda\\lib\\site-packages\\joblib\\parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"E:\\Anaconda\\lib\\site-packages\\joblib\\parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"E:\\Anaconda\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"E:\\Anaconda\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"E:\\Anaconda\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"E:\\Anaconda\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"E:\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 170, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=sample_weight, check_input=False)\n",
      "  File \"E:\\Anaconda\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"E:\\Anaconda\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  n_estimators=900, min_samples_split=1, min_samples_leaf=2, max_features=auto, max_depth=80, bootstrap=False, total=   0.6s\n",
      "[CV] n_estimators=1200, min_samples_split=4, min_samples_leaf=2, max_features=sqrt, max_depth=30, bootstrap=False \n",
      "[CV]  n_estimators=1200, min_samples_split=4, min_samples_leaf=2, max_features=sqrt, max_depth=30, bootstrap=False, total= 1.6min\n",
      "[CV] n_estimators=1200, min_samples_split=4, min_samples_leaf=2, max_features=sqrt, max_depth=30, bootstrap=False \n",
      "[CV]  n_estimators=1200, min_samples_split=4, min_samples_leaf=2, max_features=sqrt, max_depth=30, bootstrap=False, total= 1.4min\n",
      "[CV] n_estimators=1200, min_samples_split=4, min_samples_leaf=2, max_features=sqrt, max_depth=30, bootstrap=False \n",
      "[CV]  n_estimators=1200, min_samples_split=4, min_samples_leaf=2, max_features=sqrt, max_depth=30, bootstrap=False, total= 1.7min\n",
      "[CV] n_estimators=1600, min_samples_split=1, min_samples_leaf=2, max_features=sqrt, max_depth=10, bootstrap=False \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Anaconda\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\Anaconda\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"E:\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"E:\\Anaconda\\lib\\site-packages\\joblib\\parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"E:\\Anaconda\\lib\\site-packages\\joblib\\parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"E:\\Anaconda\\lib\\site-packages\\joblib\\parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"E:\\Anaconda\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"E:\\Anaconda\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"E:\\Anaconda\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"E:\\Anaconda\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"E:\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 170, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=sample_weight, check_input=False)\n",
      "  File \"E:\\Anaconda\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"E:\\Anaconda\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  n_estimators=1600, min_samples_split=1, min_samples_leaf=2, max_features=sqrt, max_depth=10, bootstrap=False, total=   1.3s\n",
      "[CV] n_estimators=1600, min_samples_split=1, min_samples_leaf=2, max_features=sqrt, max_depth=10, bootstrap=False \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Anaconda\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\Anaconda\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"E:\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"E:\\Anaconda\\lib\\site-packages\\joblib\\parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"E:\\Anaconda\\lib\\site-packages\\joblib\\parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"E:\\Anaconda\\lib\\site-packages\\joblib\\parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"E:\\Anaconda\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"E:\\Anaconda\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"E:\\Anaconda\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"E:\\Anaconda\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"E:\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 170, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=sample_weight, check_input=False)\n",
      "  File \"E:\\Anaconda\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"E:\\Anaconda\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  n_estimators=1600, min_samples_split=1, min_samples_leaf=2, max_features=sqrt, max_depth=10, bootstrap=False, total=   1.1s\n",
      "[CV] n_estimators=1600, min_samples_split=1, min_samples_leaf=2, max_features=sqrt, max_depth=10, bootstrap=False \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Anaconda\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\Anaconda\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"E:\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"E:\\Anaconda\\lib\\site-packages\\joblib\\parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"E:\\Anaconda\\lib\\site-packages\\joblib\\parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"E:\\Anaconda\\lib\\site-packages\\joblib\\parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"E:\\Anaconda\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"E:\\Anaconda\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"E:\\Anaconda\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"E:\\Anaconda\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"E:\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 170, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=sample_weight, check_input=False)\n",
      "  File \"E:\\Anaconda\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"E:\\Anaconda\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  n_estimators=1600, min_samples_split=1, min_samples_leaf=2, max_features=sqrt, max_depth=10, bootstrap=False, total=   1.5s\n",
      "[CV] n_estimators=1200, min_samples_split=1, min_samples_leaf=4, max_features=sqrt, max_depth=90, bootstrap=False \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Anaconda\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\Anaconda\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"E:\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"E:\\Anaconda\\lib\\site-packages\\joblib\\parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"E:\\Anaconda\\lib\\site-packages\\joblib\\parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"E:\\Anaconda\\lib\\site-packages\\joblib\\parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"E:\\Anaconda\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"E:\\Anaconda\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"E:\\Anaconda\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"E:\\Anaconda\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"E:\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 170, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=sample_weight, check_input=False)\n",
      "  File \"E:\\Anaconda\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"E:\\Anaconda\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  n_estimators=1200, min_samples_split=1, min_samples_leaf=4, max_features=sqrt, max_depth=90, bootstrap=False, total=   1.1s\n",
      "[CV] n_estimators=1200, min_samples_split=1, min_samples_leaf=4, max_features=sqrt, max_depth=90, bootstrap=False \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Anaconda\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\Anaconda\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"E:\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"E:\\Anaconda\\lib\\site-packages\\joblib\\parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"E:\\Anaconda\\lib\\site-packages\\joblib\\parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"E:\\Anaconda\\lib\\site-packages\\joblib\\parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"E:\\Anaconda\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"E:\\Anaconda\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"E:\\Anaconda\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"E:\\Anaconda\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"E:\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 170, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=sample_weight, check_input=False)\n",
      "  File \"E:\\Anaconda\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"E:\\Anaconda\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  n_estimators=1200, min_samples_split=1, min_samples_leaf=4, max_features=sqrt, max_depth=90, bootstrap=False, total=   0.9s\n",
      "[CV] n_estimators=1200, min_samples_split=1, min_samples_leaf=4, max_features=sqrt, max_depth=90, bootstrap=False \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Anaconda\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\Anaconda\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"E:\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"E:\\Anaconda\\lib\\site-packages\\joblib\\parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"E:\\Anaconda\\lib\\site-packages\\joblib\\parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"E:\\Anaconda\\lib\\site-packages\\joblib\\parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"E:\\Anaconda\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"E:\\Anaconda\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"E:\\Anaconda\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"E:\\Anaconda\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"E:\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 170, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=sample_weight, check_input=False)\n",
      "  File \"E:\\Anaconda\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"E:\\Anaconda\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  n_estimators=1200, min_samples_split=1, min_samples_leaf=4, max_features=sqrt, max_depth=90, bootstrap=False, total=   0.9s\n",
      "[CV] n_estimators=1800, min_samples_split=2, min_samples_leaf=6, max_features=auto, max_depth=20, bootstrap=True \n",
      "[CV]  n_estimators=1800, min_samples_split=2, min_samples_leaf=6, max_features=auto, max_depth=20, bootstrap=True, total= 1.6min\n",
      "[CV] n_estimators=1800, min_samples_split=2, min_samples_leaf=6, max_features=auto, max_depth=20, bootstrap=True \n",
      "[CV]  n_estimators=1800, min_samples_split=2, min_samples_leaf=6, max_features=auto, max_depth=20, bootstrap=True, total= 1.5min\n",
      "[CV] n_estimators=1800, min_samples_split=2, min_samples_leaf=6, max_features=auto, max_depth=20, bootstrap=True \n",
      "[CV]  n_estimators=1800, min_samples_split=2, min_samples_leaf=6, max_features=auto, max_depth=20, bootstrap=True, total= 1.6min\n",
      "[CV] n_estimators=800, min_samples_split=4, min_samples_leaf=6, max_features=auto, max_depth=80, bootstrap=False \n",
      "[CV]  n_estimators=800, min_samples_split=4, min_samples_leaf=6, max_features=auto, max_depth=80, bootstrap=False, total= 1.1min\n",
      "[CV] n_estimators=800, min_samples_split=4, min_samples_leaf=6, max_features=auto, max_depth=80, bootstrap=False \n",
      "[CV]  n_estimators=800, min_samples_split=4, min_samples_leaf=6, max_features=auto, max_depth=80, bootstrap=False, total= 1.1min\n",
      "[CV] n_estimators=800, min_samples_split=4, min_samples_leaf=6, max_features=auto, max_depth=80, bootstrap=False \n",
      "[CV]  n_estimators=800, min_samples_split=4, min_samples_leaf=6, max_features=auto, max_depth=80, bootstrap=False, total= 1.1min\n",
      "[CV] n_estimators=1800, min_samples_split=4, min_samples_leaf=2, max_features=sqrt, max_depth=50, bootstrap=False \n",
      "[CV]  n_estimators=1800, min_samples_split=4, min_samples_leaf=2, max_features=sqrt, max_depth=50, bootstrap=False, total= 2.5min\n",
      "[CV] n_estimators=1800, min_samples_split=4, min_samples_leaf=2, max_features=sqrt, max_depth=50, bootstrap=False \n",
      "[CV]  n_estimators=1800, min_samples_split=4, min_samples_leaf=2, max_features=sqrt, max_depth=50, bootstrap=False, total= 2.3min\n",
      "[CV] n_estimators=1800, min_samples_split=4, min_samples_leaf=2, max_features=sqrt, max_depth=50, bootstrap=False \n",
      "[CV]  n_estimators=1800, min_samples_split=4, min_samples_leaf=2, max_features=sqrt, max_depth=50, bootstrap=False, total= 2.4min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  30 out of  30 | elapsed: 31.0min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=3, estimator=RandomForestClassifier(),\n",
       "                   param_distributions={'bootstrap': [True, False],\n",
       "                                        'max_depth': [10, 20, 30, 40, 50, 60,\n",
       "                                                      70, 80, 90],\n",
       "                                        'max_features': ['auto', 'sqrt'],\n",
       "                                        'min_samples_leaf': [2, 4, 6],\n",
       "                                        'min_samples_split': [1, 2, 4],\n",
       "                                        'n_estimators': [200, 300, 400, 500,\n",
       "                                                         600, 700, 800, 900,\n",
       "                                                         1000, 1100, 1200, 1300,\n",
       "                                                         1400, 1500, 1600, 1700,\n",
       "                                                         1800, 1900]},\n",
       "                   random_state=42, verbose=2)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#使用随机搜索找到最佳模型\n",
    "#树的个数\n",
    "n_estimators = [int(x) for x in range(200, 2000, 100)]\n",
    "min_samples_leaf = [2, 4, 6]\n",
    "min_samples_split = [1, 2, 4]\n",
    "max_features = ['auto', 'sqrt']\n",
    "bootstrap = [True, False]\n",
    "max_depth = [int(x) for x in range(10, 100, 10)]\n",
    "param_random = {\n",
    "    'n_estimators': n_estimators,\n",
    "    'max_depth': max_depth,\n",
    "    'max_features': max_features,\n",
    "    'min_samples_leaf': min_samples_leaf,\n",
    "    'min_samples_split': min_samples_split,\n",
    "    'bootstrap': bootstrap\n",
    "}\n",
    "\n",
    "rf = RandomForestClassifier()\n",
    "rf_random = RandomizedSearchCV(estimator=rf, param_distributions=param_random, cv=3, verbose=2,\n",
    "                               random_state=42)\n",
    "rf_random.fit(x_train, y_train)\n",
    "# 获得最好的训练模型\n",
    "best_estimator = rf_random.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_forest = rf_random.best_estimator_\n",
    "#random_forest.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(max_depth=30, max_features='sqrt', min_samples_leaf=2,\n",
       "                       min_samples_split=4, n_estimators=1600)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = random_forest.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "cm1 = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "#展示混淆矩阵中的各项指标\n",
    "def show(cm):\n",
    "    TP = cm[1,1]\n",
    "    FN = cm[1,0]\n",
    "    FP = cm[0,1]\n",
    "    TN = cm[0,0]\n",
    "\n",
    "    accuracy = (TP/(TP+FN)+(TN/(TN+FP)))/2\n",
    "    P = TP/(TP+FP)\n",
    "    R = TP/(TP+FN)\n",
    "    F1 = 2/(1/P+1/R)\n",
    "\n",
    "    print(\"accracy:\",accuracy)\n",
    "    print(\"P:\",P)\n",
    "    print(\"R:\",R)\n",
    "    print(\"F1:\",F1)\n",
    "    return R"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[12110,    33],\n",
       "       [   91,   325]], dtype=int64)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accracy: 0.8892661924565594\n",
      "P: 0.9078212290502793\n",
      "R: 0.78125\n",
      "F1: 0.8397932816537468\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.78125"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cm1\n",
    "show(cm1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "#XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import roc_curve,auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Anaconda\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[20:36:46] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[20:36:46] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[20:36:47] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[20:36:48] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[20:36:48] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[20:36:49] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[20:36:49] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[20:36:50] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[20:36:50] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[20:36:51] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[20:36:51] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[20:36:52] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[20:36:53] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[20:36:53] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[20:36:54] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[20:36:55] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[20:36:55] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[20:36:56] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[20:36:56] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[20:36:57] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[20:36:58] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[20:36:58] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[20:36:59] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[20:37:00] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[20:37:00] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[20:37:01] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[20:37:02] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[20:37:03] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[20:37:03] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[20:37:04] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[20:37:05] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[20:37:06] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[20:37:06] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[20:37:07] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[20:37:08] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[20:37:09] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[20:37:09] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[20:37:10] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[20:37:11] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[20:37:12] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[20:37:13] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[20:37:13] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[20:37:14] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[20:37:15] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[20:37:16] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[20:37:17] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[20:37:18] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[20:37:18] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[20:37:19] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[20:37:20] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[20:37:21] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[20:37:22] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[20:37:23] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[20:37:24] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[20:37:25] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[20:37:26] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[20:37:27] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[20:37:28] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[20:37:28] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[20:37:29] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[20:37:30] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[20:37:31] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[20:37:32] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[20:37:33] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[20:37:34] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[20:37:35] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[20:37:36] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[20:37:37] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[20:37:38] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[20:37:39] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[20:37:40] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[20:37:41] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[20:37:42] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[20:37:43] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[20:37:44] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[20:37:46] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[20:37:47] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[20:37:48] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[20:37:49] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[20:37:50] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[20:37:51] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[20:37:52] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[20:37:53] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[20:37:54] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[20:37:55] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[20:37:57] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[20:37:58] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[20:37:59] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[20:38:00] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[20:38:01] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[20:38:02] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[20:38:03] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[20:38:03] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[20:38:04] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[20:38:05] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[20:38:05] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[20:38:06] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[20:38:06] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[20:38:07] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[20:38:08] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[20:38:08] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[20:38:09] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[20:38:10] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[20:38:10] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[20:38:11] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[20:38:12] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[20:38:12] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[20:38:13] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[20:38:14] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[20:38:14] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[20:38:15] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[20:38:16] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[20:38:17] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[20:38:17] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[20:38:18] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[20:38:19] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[20:38:20] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[20:38:20] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[20:38:21] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[20:38:22] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[20:38:23] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[20:38:24] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[20:38:24] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[20:38:25] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[20:38:26] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[20:38:27] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[20:38:28] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[20:38:29] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[20:38:29] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[20:38:30] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[20:38:31] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[20:38:32] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[20:38:33] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[20:38:34] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[20:38:35] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[20:38:36] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[20:38:37] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[20:38:38] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[20:38:38] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[20:38:39] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[20:38:40] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[20:38:41] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[20:38:42] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[20:38:43] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[20:38:44] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[20:38:45] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[20:38:46] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[20:38:47] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[20:38:48] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[20:38:49] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[20:38:50] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[20:38:52] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[20:38:53] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[20:38:54] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[20:38:55] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[20:38:56] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[20:38:57] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[20:38:58] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[20:38:59] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[20:39:01] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[20:39:02] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[20:39:03] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[20:39:04] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[20:39:05] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[20:39:06] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[20:39:07] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[20:39:09] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[20:39:10] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[20:39:12] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[20:39:13] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[20:39:14] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[20:39:16] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[20:39:17] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[20:39:19] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[20:39:20] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[20:39:22] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[20:39:23] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[20:39:25] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[20:39:26] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[20:39:27] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[20:39:29] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[20:39:29] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[20:39:30] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[20:39:30] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[20:39:31] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[20:39:32] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[20:39:32] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[20:39:33] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[20:39:34] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[20:39:34] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[20:39:35] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[20:39:36] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[20:39:37] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[20:39:37] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[20:39:38] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[20:39:39] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[20:39:40] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[20:39:40] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[20:39:41] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[20:39:42] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[20:39:43] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[20:39:43] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[20:39:44] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[20:39:45] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[20:39:46] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[20:39:47] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[20:39:48] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[20:39:48] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[20:39:49] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[20:39:50] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[20:39:51] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[20:39:52] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[20:39:53] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[20:39:54] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[20:39:55] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[20:39:56] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[20:39:57] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[20:39:57] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[20:39:58] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[20:39:59] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[20:40:00] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[20:40:01] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[20:40:02] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[20:40:03] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[20:40:04] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[20:40:05] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[20:40:06] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[20:40:07] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[20:40:08] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[20:40:09] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[20:40:11] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[20:40:12] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[20:40:13] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[20:40:14] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[20:40:15] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[20:40:16] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[20:40:17] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[20:40:18] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[20:40:19] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[20:40:20] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[20:40:22] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[20:40:23] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[20:40:24] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[20:40:25] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[20:40:26] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[20:40:27] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[20:40:29] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[20:40:30] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[20:40:31] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[20:40:32] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[20:40:33] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[20:40:35] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[20:40:36] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[20:40:37] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[20:40:38] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[20:40:40] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[20:40:41] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[20:40:42] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[20:40:44] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[20:40:45] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[20:40:46] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[20:40:48] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[20:40:49] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[20:40:50] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[20:40:52] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[20:40:53] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[20:40:54] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[20:40:56] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[20:40:57] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[20:40:58] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[20:41:00] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=3,\n",
       "             estimator=XGBClassifier(base_score=None, booster=None,\n",
       "                                     colsample_bylevel=None,\n",
       "                                     colsample_bynode=None,\n",
       "                                     colsample_bytree=None, gamma=None,\n",
       "                                     gpu_id=None, importance_type='gain',\n",
       "                                     interaction_constraints=None,\n",
       "                                     learning_rate=None, max_delta_step=None,\n",
       "                                     max_depth=None, min_child_weight=None,\n",
       "                                     missing=nan, monotone_constraints=None,\n",
       "                                     n_estimators=100, n_jobs=None,\n",
       "                                     num_parallel_tree=None, random_state=None,\n",
       "                                     reg_alpha=None, reg_lambda=None,\n",
       "                                     scale_pos_weight=None, subsample=None,\n",
       "                                     tree_method=None, validate_parameters=None,\n",
       "                                     verbosity=None),\n",
       "             param_grid={'colsample_bytree': array([0.5 , 0.75, 1.  ]),\n",
       "                         'n_estimators': range(80, 200, 4),\n",
       "                         'scale_pos_weight': [10]},\n",
       "             scoring='f1')"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf1 = xgb.XGBClassifier()\n",
    "param_dist = {\n",
    "        'n_estimators':range(80,200,4),    \n",
    "        'colsample_bytree':np.linspace(0.5,1,3),\n",
    "        'scale_pos_weight':[10]\n",
    "        }\n",
    "#使用网格搜索法找到最佳参数\n",
    "grid = GridSearchCV(clf1,param_dist,cv = 3,scoring = 'f1')\n",
    "\n",
    "grid.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
      "              colsample_bynode=1, colsample_bytree=0.75, gamma=0, gpu_id=-1,\n",
      "              importance_type='gain', interaction_constraints='',\n",
      "              learning_rate=0.300000012, max_delta_step=0, max_depth=6,\n",
      "              min_child_weight=1, missing=nan, monotone_constraints='()',\n",
      "              n_estimators=180, n_jobs=4, num_parallel_tree=1, random_state=0,\n",
      "              reg_alpha=0, reg_lambda=1, scale_pos_weight=10, subsample=1,\n",
      "              tree_method='exact', validate_parameters=1, verbosity=None)\n"
     ]
    }
   ],
   "source": [
    "XGB = grid.best_estimator_\n",
    "print(XGB)\n",
    "\n",
    "y_predict = XGB.predict(x_test)\n",
    "cm2 = confusion_matrix(y_test,y_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[12068,    75],\n",
       "       [   66,   350]], dtype=int64)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accracy: 0.9175848779607118\n",
      "P: 0.8235294117647058\n",
      "R: 0.8413461538461539\n",
      "F1: 0.8323424494649226\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8413461538461539"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cm2\n",
    "show(cm2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SVM\n",
    "from sklearn import svm\n",
    "clf = svm.SVC()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 14 candidates, totalling 70 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=8)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done  34 tasks      | elapsed:  3.7min\n",
      "[Parallel(n_jobs=8)]: Done  70 out of  70 | elapsed:  6.0min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(estimator=SVC(probability=True), n_jobs=8,\n",
       "             param_grid={'C': [0.001, 0.01, 0.1, 1, 10, 100, 1000],\n",
       "                         'gamma': [0.001, 0.0001]},\n",
       "             verbose=1)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = svm.SVC(kernel='rbf', probability=True)\n",
    "param_grid = {'C': [1e-3, 1e-2, 1e-1, 1, 10, 100, 1000], 'gamma': [0.001, 0.0001]}\n",
    "grid_search = GridSearchCV(model, param_grid, n_jobs = 8, verbose=1)\n",
    "grid_search.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVC(C=1000, gamma=0.001, probability=True)\n"
     ]
    }
   ],
   "source": [
    "svm = grid_search.best_estimator_\n",
    "print(svm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predict = svm.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[12103,    40],\n",
       "       [  124,   292]], dtype=int64)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accracy: 0.8493144990149437\n",
      "P: 0.8795180722891566\n",
      "R: 0.7019230769230769\n",
      "F1: 0.7807486631016043\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7019230769230769"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cm3 = confusion_matrix(y_test,y_predict)\n",
    "cm3\n",
    "show(cm3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "#logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accracy: 0.8525085083840642\n",
      "P: 0.855072463768116\n",
      "R: 0.7091346153846154\n",
      "F1: 0.7752956636005256\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7091346153846154"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "lr_model = LogisticRegression() #调用逻辑回归模型\n",
    "lr_model.fit(x_train,y_train)\n",
    "y_predict = lr_model.predict(x_test)\n",
    "cm4 = confusion_matrix(y_test,y_predict)\n",
    "show(cm4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[12093,    50],\n",
       "       [  121,   295]], dtype=int64)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accracy: 0.8525085083840642\n",
      "P: 0.855072463768116\n",
      "R: 0.7091346153846154\n",
      "F1: 0.7752956636005256\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7091346153846154"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cm4\n",
    "show(cm4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MLPClassifier(hidden_layer_sizes=5)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accracy: 0.860839617950196\n",
      "P: 0.8531073446327684\n",
      "R: 0.7259615384615384\n",
      "F1: 0.7844155844155843\n",
      "accracy: 0.860839617950196\n",
      "P: 0.8531073446327684\n",
      "R: 0.7259615384615384\n",
      "F1: 0.7844155844155843\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLPClassifier(hidden_layer_sizes=20)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accracy: 0.8637453954161625\n",
      "P: 0.8155080213903744\n",
      "R: 0.7331730769230769\n",
      "F1: 0.7721518987341773\n",
      "accracy: 0.8637453954161625\n",
      "P: 0.8155080213903744\n",
      "R: 0.7331730769230769\n",
      "F1: 0.7721518987341773\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLPClassifier(hidden_layer_sizes=50)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accracy: 0.8454616738671852\n",
      "P: 0.8626865671641791\n",
      "R: 0.6947115384615384\n",
      "F1: 0.7696404793608522\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLPClassifier(hidden_layer_sizes=100)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accracy: 0.8831075120835683\n",
      "P: 0.7721822541966427\n",
      "R: 0.7740384615384616\n",
      "F1: 0.773109243697479\n",
      "accracy: 0.8831075120835683\n",
      "P: 0.7721822541966427\n",
      "R: 0.7740384615384616\n",
      "F1: 0.773109243697479\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLPClassifier(hidden_layer_sizes=200)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accracy: 0.8639924513331517\n",
      "P: 0.8288043478260869\n",
      "R: 0.7331730769230769\n",
      "F1: 0.7780612244897959\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLPClassifier(hidden_layer_sizes=1000)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accracy: 0.8551594104548996\n",
      "P: 0.8709677419354839\n",
      "R: 0.7139423076923077\n",
      "F1: 0.7846763540290621\n"
     ]
    }
   ],
   "source": [
    "#Neural Network\n",
    "from sklearn import neural_network\n",
    "R = 0\n",
    "\n",
    "for i in [5,20,50,100,200,1000]:\n",
    "    mlp=neural_network.MLPClassifier(hidden_layer_sizes=(i), #隐藏层\n",
    "                                     #（10,20）指的是隐藏层层数+每层单元数\n",
    "                                    activation='relu',  #激活函数\n",
    "                                    solver='adam',\n",
    "                                    alpha=0.0001,  #正则化项系数\n",
    "                                    batch_size='auto',\n",
    "                                    learning_rate='constant',  #学习率\n",
    "                                    learning_rate_init=0.001,\n",
    "                                    power_t=0.5,\n",
    "                                    max_iter=200,  #迭代次数\n",
    "                                    tol=1e-4)\n",
    "    mlp.fit(x_train,y_train)\n",
    "    y_predict = mlp.predict(x_test)\n",
    "    cm5 = confusion_matrix(y_test,y_predict)\n",
    "    if show(cm5)>R:\n",
    "        R = show(cm5)\n",
    "        best_estimator = mlp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MLPClassifier(hidden_layer_sizes=100)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "0.7740384615384616"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_estimator\n",
    "R"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[12048,    95],\n",
       "       [   94,   322]], dtype=int64)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cm5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[12048,    95],\n",
       "       [   94,   322]], dtype=int64)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accracy: 0.8831075120835683\n",
      "P: 0.7721822541966427\n",
      "R: 0.7740384615384616\n",
      "F1: 0.773109243697479\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7740384615384616"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#mlp.fit(x_train,y_train)\n",
    "y_predict = best_estimator.predict(x_test)\n",
    "cm5 = confusion_matrix(y_test,y_predict)\n",
    "cm5\n",
    "show(cm5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "import textdistance\n",
    "def clean_string(str1):\n",
    "    str1 = str1.lower()\n",
    "    str1 =str1.replace('mr.','')\n",
    "    str1 =str1.replace('mrs.','')\n",
    "    str1 =str1.replace('\\n',' \\n')\n",
    "    str1 =str1.replace('\\n',' \\n')\n",
    "    str1 =str1.replace('\\n',' \\n')\n",
    "    str1 =str1.replace('.',' ')\n",
    "    str1 =str1.replace(',',' ')\n",
    "    str1 =str1.replace('\\'','')\n",
    "    str1 =str1.replace(' & ',' and ')\n",
    "    str1 =str1.replace(' &',' and ')\n",
    "    str1 =str1.replace('& ',' and ')\n",
    "    str1 =str1.replace('&',' and ')\n",
    "    str1 =str1.replace(' l p ',' lp ')\n",
    "    str1 =str1.replace('l l p ','llp ')\n",
    "    str1 =str1.replace('l l c ','llc ')\n",
    "    str1 =str1.replace(' ltd ',' limited ')\n",
    "    str1 =str1.replace(' p l c ',' plc')\n",
    "    str1 =str1.replace(' co ltd ',' company limited ')\n",
    "    str1 =str1.replace(' co ',' company ')\n",
    "    str1 =str1.replace(' corp ',' corporation ')\n",
    "    str1 =str1.replace(' univ ',' university ')\n",
    "    str1 =str1.replace(' fdtn ',' foundation ')\n",
    "    str1 =str1.replace(' inc ',' incorporated ')\n",
    "    str1 =str1.replace(' assoc ',' association ')\n",
    "    str1 =str1.replace(' mgmt ',' management ')\n",
    "    str1 =str1.replace(' svsc ',' services ')\n",
    "    str1 =str1.replace(' ag ',' aktiengesellschaft ')\n",
    "    str1 =str1.replace(' govt ',' goverment ')\n",
    "    str1 =str1.replace(' svgs ',' savings ')\n",
    "    str1 =str1.replace(' intl ',' international ')\n",
    "    str1 =str1.replace('intl ','international ')\n",
    "    str1 =str1.replace(' investmentco lt ',' investment company limited ')\n",
    "    str1 = str1.replace('the ','')\n",
    "    str1 = str1.replace(' the ','')\n",
    "    str1 = str1.strip()\n",
    "    return str1\n",
    "\n",
    "def InStringSerch(a,b):\n",
    "    return int(a in b or b in a)\n",
    "\n",
    "\n",
    "def get_similarity(a,b):\n",
    "    a = clean_string(a)\n",
    "    b = clean_string(b)\n",
    "    Cosine_Similarity = textdistance.cosine.similarity(a,b)\n",
    "    Levenshtein_Distance = textdistance.levenshtein.distance(a,b)\n",
    "    Jaro_Winkler_Distance = textdistance.jaro_winkler.similarity(a,b)\n",
    "    Jaccard_Index = textdistance.jaccard.similarity(a,b)\n",
    "    Monge_Elkan = textdistance.monge_elkan.similarity(a,b)\n",
    "    MRA = textdistance.mra.similarity(a,b)\n",
    "    Longest_Common_Substring = textdistance.lcsstr.similarity(a,b)\n",
    "    Longest_Common_ubsequence = textdistance.lcsseq.similarity(a,b)\n",
    "    In_String_Search = InStringSerch(a,b)\n",
    "    return pd.DataFrame({'Cosine Similarity':Cosine_Similarity,'Levenshtein Distance':Levenshtein_Distance,\n",
    "            'Jaro-Winkler Distance':Jaro_Winkler_Distance,'Jaccard Index':Jaccard_Index,'Monge Elkan':Monge_Elkan,\n",
    "            'MRA':MRA,'Longest Common Substring':Longest_Common_Substring,\n",
    "            'Longest Common Subsequence':Longest_Common_ubsequence,'In String Search':In_String_Search},index = [0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = 'avs'\n",
    "b = 'acs sdw'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Cosine Similarity</th>\n",
       "      <th>Levenshtein Distance</th>\n",
       "      <th>Jaro-Winkler Distance</th>\n",
       "      <th>Jaccard Index</th>\n",
       "      <th>Monge Elkan</th>\n",
       "      <th>MRA</th>\n",
       "      <th>Longest Common Substring</th>\n",
       "      <th>Longest Common Subsequence</th>\n",
       "      <th>In String Search</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.436436</td>\n",
       "      <td>5</td>\n",
       "      <td>0.650794</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Cosine Similarity  Levenshtein Distance  Jaro-Winkler Distance  \\\n",
       "0           0.436436                     5               0.650794   \n",
       "\n",
       "   Jaccard Index  Monge Elkan  MRA  Longest Common Substring  \\\n",
       "0           0.25     0.222222    0                         1   \n",
       "\n",
       "   Longest Common Subsequence  In String Search  \n",
       "0                           2                 0  "
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_similarity(a,b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "请输入第一个字符串:a\n",
      "请输入第二个字符串:b\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Cosine Similarity</th>\n",
       "      <th>Levenshtein Distance</th>\n",
       "      <th>Jaro-Winkler Distance</th>\n",
       "      <th>Jaccard Index</th>\n",
       "      <th>Monge Elkan</th>\n",
       "      <th>MRA</th>\n",
       "      <th>Longest Common Substring</th>\n",
       "      <th>Longest Common Subsequence</th>\n",
       "      <th>In String Search</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Cosine Similarity  Levenshtein Distance  Jaro-Winkler Distance  \\\n",
       "0                0.0                     1                    0.0   \n",
       "\n",
       "   Jaccard Index  Monge Elkan  MRA  Longest Common Substring  \\\n",
       "0            0.0          0.0    0                         0   \n",
       "\n",
       "   Longest Common Subsequence  In String Search  \n",
       "0                           0                 0  "
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "您输入的字符串分别为：a , b\n",
      "Not Match\n"
     ]
    }
   ],
   "source": [
    "a = input(\"请输入第一个字符串:\")\n",
    "b = input(\"请输入第二个字符串:\")\n",
    "get_similarity(a,b)\n",
    "print('您输入的字符串分别为：'+str(a)+' , '+str(b))\n",
    "print(['Match' if random_forest.predict(get_similarity(a,b))[0]==1 else 'Not Match'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get(cm):\n",
    "    TP = cm[1,1]\n",
    "    FN = cm[1,0]\n",
    "    FP = cm[0,1]\n",
    "    TN = cm[0,0]\n",
    "\n",
    "    accuracy = (TP/(TP+FN)+(TN/(TN+FP)))/2\n",
    "    P = TP/(TP+FP)\n",
    "    R = TP/(TP+FN)\n",
    "    F1 = 2/(1/P+1/R)\n",
    "\n",
    "    return [accuracy,P,R,F1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm_list = [cm1,cm2,cm3,cm4,cm5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "dic = {}\n",
    "dic['accuracy'] = [get(i)[0] for i in cm_list]\n",
    "dic['P'] = [get(i)[1] for i in cm_list]\n",
    "dic['R'] = [get(i)[2] for i in cm_list]\n",
    "dic['F1'] = [get(i)[3] for i in cm_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accuracy</th>\n",
       "      <th>P</th>\n",
       "      <th>R</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>random_forest</th>\n",
       "      <td>0.889266</td>\n",
       "      <td>0.907821</td>\n",
       "      <td>0.781250</td>\n",
       "      <td>0.839793</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>xgboost</th>\n",
       "      <td>0.917585</td>\n",
       "      <td>0.823529</td>\n",
       "      <td>0.841346</td>\n",
       "      <td>0.832342</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>svm</th>\n",
       "      <td>0.849314</td>\n",
       "      <td>0.879518</td>\n",
       "      <td>0.701923</td>\n",
       "      <td>0.780749</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>logistic_regression</th>\n",
       "      <td>0.852509</td>\n",
       "      <td>0.855072</td>\n",
       "      <td>0.709135</td>\n",
       "      <td>0.775296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Neural Network</th>\n",
       "      <td>0.883108</td>\n",
       "      <td>0.772182</td>\n",
       "      <td>0.774038</td>\n",
       "      <td>0.773109</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     accuracy         P         R        F1\n",
       "random_forest        0.889266  0.907821  0.781250  0.839793\n",
       "xgboost              0.917585  0.823529  0.841346  0.832342\n",
       "svm                  0.849314  0.879518  0.701923  0.780749\n",
       "logistic_regression  0.852509  0.855072  0.709135  0.775296\n",
       "Neural Network       0.883108  0.772182  0.774038  0.773109"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(dic,index = ['random_forest','xgboost','svm','logistic_regression','Neural Network'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "重要性： [0.05242855 0.06498706 0.06220461 0.04949156 0.04196309 0.04353179\n",
      " 0.570612   0.08481203 0.0299693 ]\n"
     ]
    }
   ],
   "source": [
    "importances = XGB.feature_importances_\n",
    "print(\"重要性：\",importances)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "pd.Series(importances,index = x_train.columns).plot(kind = 'bar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
