{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\" \n",
    "#实现多输出\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.mlab as mlab  \n",
    "import matplotlib.pyplot as plt  \n",
    "import jieba\n",
    "import textdistance\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>PRIMARY_NAME</th>\n",
       "      <th>ALT_NAME</th>\n",
       "      <th>State</th>\n",
       "      <th>Cosine Similarity</th>\n",
       "      <th>Levenshtein Distance</th>\n",
       "      <th>Jaro-Winkler Distance</th>\n",
       "      <th>Jaccard Index</th>\n",
       "      <th>Monge Elkan</th>\n",
       "      <th>MRA</th>\n",
       "      <th>Longest Common Substring</th>\n",
       "      <th>Longest Common Subsequence</th>\n",
       "      <th>In String Search</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>gazprombank upravlenie aktivami</td>\n",
       "      <td>gazprombank asset management zao</td>\n",
       "      <td>Match</td>\n",
       "      <td>0.666751</td>\n",
       "      <td>15</td>\n",
       "      <td>0.847686</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.024974</td>\n",
       "      <td>4</td>\n",
       "      <td>12</td>\n",
       "      <td>18</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>gazprombank upravlenie aktivami</td>\n",
       "      <td>closed joint-stock company gazprombank-upravle...</td>\n",
       "      <td>Match</td>\n",
       "      <td>0.731083</td>\n",
       "      <td>30</td>\n",
       "      <td>0.683537</td>\n",
       "      <td>0.534483</td>\n",
       "      <td>0.032258</td>\n",
       "      <td>3</td>\n",
       "      <td>19</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>united instrument manufacturing corporation</td>\n",
       "      <td>jsc-united-instrument-manufacturing-corporation</td>\n",
       "      <td>Match</td>\n",
       "      <td>0.889768</td>\n",
       "      <td>40</td>\n",
       "      <td>0.802099</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.021633</td>\n",
       "      <td>3</td>\n",
       "      <td>13</td>\n",
       "      <td>40</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>gaz-oil  ooo</td>\n",
       "      <td>gaz-oil</td>\n",
       "      <td>Match</td>\n",
       "      <td>0.763763</td>\n",
       "      <td>7</td>\n",
       "      <td>0.916667</td>\n",
       "      <td>0.583333</td>\n",
       "      <td>0.069444</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>ken wong</td>\n",
       "      <td>ken wong kaw</td>\n",
       "      <td>Match</td>\n",
       "      <td>0.816497</td>\n",
       "      <td>8</td>\n",
       "      <td>0.933333</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                 PRIMARY_NAME  \\\n",
       "0           0              gazprombank upravlenie aktivami   \n",
       "1           1              gazprombank upravlenie aktivami   \n",
       "2           2  united instrument manufacturing corporation   \n",
       "3           3                                 gaz-oil  ooo   \n",
       "4           4                                     ken wong   \n",
       "\n",
       "                                            ALT_NAME  State  \\\n",
       "0                   gazprombank asset management zao  Match   \n",
       "1  closed joint-stock company gazprombank-upravle...  Match   \n",
       "2    jsc-united-instrument-manufacturing-corporation  Match   \n",
       "3                                            gaz-oil  Match   \n",
       "4                                       ken wong kaw  Match   \n",
       "\n",
       "   Cosine Similarity  Levenshtein Distance  Jaro-Winkler Distance  \\\n",
       "0           0.666751                    15               0.847686   \n",
       "1           0.731083                    30               0.683537   \n",
       "2           0.889768                    40               0.802099   \n",
       "3           0.763763                     7               0.916667   \n",
       "4           0.816497                     8               0.933333   \n",
       "\n",
       "   Jaccard Index  Monge Elkan  MRA  Longest Common Substring  \\\n",
       "0       0.500000     0.024974    4                        12   \n",
       "1       0.534483     0.032258    3                        19   \n",
       "2       0.800000     0.021633    3                        13   \n",
       "3       0.583333     0.069444    4                         7   \n",
       "4       0.666667     0.125000    3                         8   \n",
       "\n",
       "   Longest Common Subsequence  In String Search  \n",
       "0                          18                 0  \n",
       "1                          30                 0  \n",
       "2                          40                 0  \n",
       "3                           7                 1  \n",
       "4                           8                 1  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_excel('data.xlsx')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#随机森林"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import RandomizedSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = data.iloc[:,4:]\n",
    "y = data.iloc[:,3]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f(y):\n",
    "    if y=='Match':\n",
    "        return 1\n",
    "    else: \n",
    "        return 0\n",
    "y = [f(y) for y in y.values]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train,x_test,y_train,y_test = train_test_split(x,y,test_size=0.3,random_state=0)  #构建训练集以及测试集用于模型的构建"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Cosine Similarity</th>\n",
       "      <th>Levenshtein Distance</th>\n",
       "      <th>Jaro-Winkler Distance</th>\n",
       "      <th>Jaccard Index</th>\n",
       "      <th>Monge Elkan</th>\n",
       "      <th>MRA</th>\n",
       "      <th>Longest Common Substring</th>\n",
       "      <th>Longest Common Subsequence</th>\n",
       "      <th>In String Search</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>25550</th>\n",
       "      <td>0.431517</td>\n",
       "      <td>4</td>\n",
       "      <td>0.478065</td>\n",
       "      <td>0.257143</td>\n",
       "      <td>0.048889</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27440</th>\n",
       "      <td>0.521749</td>\n",
       "      <td>3</td>\n",
       "      <td>0.583333</td>\n",
       "      <td>0.350000</td>\n",
       "      <td>0.048611</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2491</th>\n",
       "      <td>0.606103</td>\n",
       "      <td>10</td>\n",
       "      <td>0.618176</td>\n",
       "      <td>0.418182</td>\n",
       "      <td>0.028889</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25726</th>\n",
       "      <td>0.480015</td>\n",
       "      <td>6</td>\n",
       "      <td>0.545622</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>0.056122</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21802</th>\n",
       "      <td>0.583874</td>\n",
       "      <td>5</td>\n",
       "      <td>0.558153</td>\n",
       "      <td>0.405405</td>\n",
       "      <td>0.039256</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20757</th>\n",
       "      <td>0.849706</td>\n",
       "      <td>19</td>\n",
       "      <td>0.920947</td>\n",
       "      <td>0.730769</td>\n",
       "      <td>0.050000</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>19</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32103</th>\n",
       "      <td>0.417029</td>\n",
       "      <td>4</td>\n",
       "      <td>0.372786</td>\n",
       "      <td>0.230769</td>\n",
       "      <td>0.074074</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30403</th>\n",
       "      <td>0.576557</td>\n",
       "      <td>9</td>\n",
       "      <td>0.559219</td>\n",
       "      <td>0.379310</td>\n",
       "      <td>0.014053</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21243</th>\n",
       "      <td>0.376309</td>\n",
       "      <td>6</td>\n",
       "      <td>0.421523</td>\n",
       "      <td>0.187500</td>\n",
       "      <td>0.008264</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2732</th>\n",
       "      <td>0.535303</td>\n",
       "      <td>6</td>\n",
       "      <td>0.549708</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.046296</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>25808 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Cosine Similarity  Levenshtein Distance  Jaro-Winkler Distance  \\\n",
       "25550           0.431517                     4               0.478065   \n",
       "27440           0.521749                     3               0.583333   \n",
       "2491            0.606103                    10               0.618176   \n",
       "25726           0.480015                     6               0.545622   \n",
       "21802           0.583874                     5               0.558153   \n",
       "...                  ...                   ...                    ...   \n",
       "20757           0.849706                    19               0.920947   \n",
       "32103           0.417029                     4               0.372786   \n",
       "30403           0.576557                     9               0.559219   \n",
       "21243           0.376309                     6               0.421523   \n",
       "2732            0.535303                     6               0.549708   \n",
       "\n",
       "       Jaccard Index  Monge Elkan  MRA  Longest Common Substring  \\\n",
       "25550       0.257143     0.048889    0                         3   \n",
       "27440       0.350000     0.048611    0                         1   \n",
       "2491        0.418182     0.028889    0                         3   \n",
       "25726       0.285714     0.056122    0                         1   \n",
       "21802       0.405405     0.039256    1                         4   \n",
       "...              ...          ...  ...                       ...   \n",
       "20757       0.730769     0.050000    3                        10   \n",
       "32103       0.230769     0.074074    0                         1   \n",
       "30403       0.379310     0.014053    0                         3   \n",
       "21243       0.187500     0.008264    1                         2   \n",
       "2732        0.333333     0.046296    0                         2   \n",
       "\n",
       "       Longest Common Subsequence  In String Search  \n",
       "25550                           6                 0  \n",
       "27440                           5                 0  \n",
       "2491                           15                 0  \n",
       "25726                           7                 0  \n",
       "21802                           9                 0  \n",
       "...                           ...               ...  \n",
       "20757                          19                 0  \n",
       "32103                           4                 0  \n",
       "30403                          11                 0  \n",
       "21243                           6                 0  \n",
       "2732                            7                 0  \n",
       "\n",
       "[25808 rows x 9 columns]"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " ...]"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 10 candidates, totalling 30 fits\n",
      "[CV] n_estimators=1600, min_samples_split=4, min_samples_leaf=2, max_features=sqrt, max_depth=30, bootstrap=True \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  n_estimators=1600, min_samples_split=4, min_samples_leaf=2, max_features=sqrt, max_depth=30, bootstrap=True, total=  44.9s\n",
      "[CV] n_estimators=1600, min_samples_split=4, min_samples_leaf=2, max_features=sqrt, max_depth=30, bootstrap=True \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:   44.8s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  n_estimators=1600, min_samples_split=4, min_samples_leaf=2, max_features=sqrt, max_depth=30, bootstrap=True, total=  42.4s\n",
      "[CV] n_estimators=1600, min_samples_split=4, min_samples_leaf=2, max_features=sqrt, max_depth=30, bootstrap=True \n",
      "[CV]  n_estimators=1600, min_samples_split=4, min_samples_leaf=2, max_features=sqrt, max_depth=30, bootstrap=True, total=  47.2s\n",
      "[CV] n_estimators=1000, min_samples_split=4, min_samples_leaf=2, max_features=sqrt, max_depth=80, bootstrap=False \n",
      "[CV]  n_estimators=1000, min_samples_split=4, min_samples_leaf=2, max_features=sqrt, max_depth=80, bootstrap=False, total=  36.7s\n",
      "[CV] n_estimators=1000, min_samples_split=4, min_samples_leaf=2, max_features=sqrt, max_depth=80, bootstrap=False \n",
      "[CV]  n_estimators=1000, min_samples_split=4, min_samples_leaf=2, max_features=sqrt, max_depth=80, bootstrap=False, total=  38.1s\n",
      "[CV] n_estimators=1000, min_samples_split=4, min_samples_leaf=2, max_features=sqrt, max_depth=80, bootstrap=False \n",
      "[CV]  n_estimators=1000, min_samples_split=4, min_samples_leaf=2, max_features=sqrt, max_depth=80, bootstrap=False, total=  37.9s\n",
      "[CV] n_estimators=800, min_samples_split=4, min_samples_leaf=2, max_features=auto, max_depth=80, bootstrap=False \n",
      "[CV]  n_estimators=800, min_samples_split=4, min_samples_leaf=2, max_features=auto, max_depth=80, bootstrap=False, total=  35.4s\n",
      "[CV] n_estimators=800, min_samples_split=4, min_samples_leaf=2, max_features=auto, max_depth=80, bootstrap=False \n",
      "[CV]  n_estimators=800, min_samples_split=4, min_samples_leaf=2, max_features=auto, max_depth=80, bootstrap=False, total=  33.1s\n",
      "[CV] n_estimators=800, min_samples_split=4, min_samples_leaf=2, max_features=auto, max_depth=80, bootstrap=False \n",
      "[CV]  n_estimators=800, min_samples_split=4, min_samples_leaf=2, max_features=auto, max_depth=80, bootstrap=False, total=  31.8s\n",
      "[CV] n_estimators=900, min_samples_split=1, min_samples_leaf=2, max_features=auto, max_depth=80, bootstrap=False \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Anaconda\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\Anaconda\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"E:\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"E:\\Anaconda\\lib\\site-packages\\joblib\\parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"E:\\Anaconda\\lib\\site-packages\\joblib\\parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"E:\\Anaconda\\lib\\site-packages\\joblib\\parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"E:\\Anaconda\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"E:\\Anaconda\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"E:\\Anaconda\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"E:\\Anaconda\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"E:\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 170, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=sample_weight, check_input=False)\n",
      "  File \"E:\\Anaconda\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"E:\\Anaconda\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  n_estimators=900, min_samples_split=1, min_samples_leaf=2, max_features=auto, max_depth=80, bootstrap=False, total=   0.5s\n",
      "[CV] n_estimators=900, min_samples_split=1, min_samples_leaf=2, max_features=auto, max_depth=80, bootstrap=False \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Anaconda\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\Anaconda\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"E:\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"E:\\Anaconda\\lib\\site-packages\\joblib\\parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"E:\\Anaconda\\lib\\site-packages\\joblib\\parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"E:\\Anaconda\\lib\\site-packages\\joblib\\parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"E:\\Anaconda\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"E:\\Anaconda\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"E:\\Anaconda\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"E:\\Anaconda\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"E:\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 170, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=sample_weight, check_input=False)\n",
      "  File \"E:\\Anaconda\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"E:\\Anaconda\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  n_estimators=900, min_samples_split=1, min_samples_leaf=2, max_features=auto, max_depth=80, bootstrap=False, total=   0.5s\n",
      "[CV] n_estimators=900, min_samples_split=1, min_samples_leaf=2, max_features=auto, max_depth=80, bootstrap=False \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Anaconda\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\Anaconda\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"E:\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"E:\\Anaconda\\lib\\site-packages\\joblib\\parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"E:\\Anaconda\\lib\\site-packages\\joblib\\parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"E:\\Anaconda\\lib\\site-packages\\joblib\\parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"E:\\Anaconda\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"E:\\Anaconda\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"E:\\Anaconda\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"E:\\Anaconda\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"E:\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 170, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=sample_weight, check_input=False)\n",
      "  File \"E:\\Anaconda\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"E:\\Anaconda\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  n_estimators=900, min_samples_split=1, min_samples_leaf=2, max_features=auto, max_depth=80, bootstrap=False, total=   0.5s\n",
      "[CV] n_estimators=1200, min_samples_split=4, min_samples_leaf=2, max_features=sqrt, max_depth=30, bootstrap=False \n",
      "[CV]  n_estimators=1200, min_samples_split=4, min_samples_leaf=2, max_features=sqrt, max_depth=30, bootstrap=False, total=  46.5s\n",
      "[CV] n_estimators=1200, min_samples_split=4, min_samples_leaf=2, max_features=sqrt, max_depth=30, bootstrap=False \n",
      "[CV]  n_estimators=1200, min_samples_split=4, min_samples_leaf=2, max_features=sqrt, max_depth=30, bootstrap=False, total=  48.9s\n",
      "[CV] n_estimators=1200, min_samples_split=4, min_samples_leaf=2, max_features=sqrt, max_depth=30, bootstrap=False \n",
      "[CV]  n_estimators=1200, min_samples_split=4, min_samples_leaf=2, max_features=sqrt, max_depth=30, bootstrap=False, total= 1.0min\n",
      "[CV] n_estimators=1600, min_samples_split=1, min_samples_leaf=2, max_features=sqrt, max_depth=10, bootstrap=False \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Anaconda\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\Anaconda\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"E:\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"E:\\Anaconda\\lib\\site-packages\\joblib\\parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"E:\\Anaconda\\lib\\site-packages\\joblib\\parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"E:\\Anaconda\\lib\\site-packages\\joblib\\parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"E:\\Anaconda\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"E:\\Anaconda\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"E:\\Anaconda\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"E:\\Anaconda\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"E:\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 170, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=sample_weight, check_input=False)\n",
      "  File \"E:\\Anaconda\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"E:\\Anaconda\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  n_estimators=1600, min_samples_split=1, min_samples_leaf=2, max_features=sqrt, max_depth=10, bootstrap=False, total=   1.0s\n",
      "[CV] n_estimators=1600, min_samples_split=1, min_samples_leaf=2, max_features=sqrt, max_depth=10, bootstrap=False \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Anaconda\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\Anaconda\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"E:\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"E:\\Anaconda\\lib\\site-packages\\joblib\\parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"E:\\Anaconda\\lib\\site-packages\\joblib\\parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"E:\\Anaconda\\lib\\site-packages\\joblib\\parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"E:\\Anaconda\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"E:\\Anaconda\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"E:\\Anaconda\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"E:\\Anaconda\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"E:\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 170, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=sample_weight, check_input=False)\n",
      "  File \"E:\\Anaconda\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"E:\\Anaconda\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  n_estimators=1600, min_samples_split=1, min_samples_leaf=2, max_features=sqrt, max_depth=10, bootstrap=False, total=   0.9s\n",
      "[CV] n_estimators=1600, min_samples_split=1, min_samples_leaf=2, max_features=sqrt, max_depth=10, bootstrap=False \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Anaconda\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\Anaconda\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"E:\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"E:\\Anaconda\\lib\\site-packages\\joblib\\parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"E:\\Anaconda\\lib\\site-packages\\joblib\\parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"E:\\Anaconda\\lib\\site-packages\\joblib\\parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"E:\\Anaconda\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"E:\\Anaconda\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"E:\\Anaconda\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"E:\\Anaconda\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"E:\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 170, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=sample_weight, check_input=False)\n",
      "  File \"E:\\Anaconda\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"E:\\Anaconda\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  n_estimators=1600, min_samples_split=1, min_samples_leaf=2, max_features=sqrt, max_depth=10, bootstrap=False, total=   0.9s\n",
      "[CV] n_estimators=1200, min_samples_split=1, min_samples_leaf=4, max_features=sqrt, max_depth=90, bootstrap=False \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Anaconda\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\Anaconda\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"E:\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"E:\\Anaconda\\lib\\site-packages\\joblib\\parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"E:\\Anaconda\\lib\\site-packages\\joblib\\parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"E:\\Anaconda\\lib\\site-packages\\joblib\\parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"E:\\Anaconda\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"E:\\Anaconda\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"E:\\Anaconda\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"E:\\Anaconda\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"E:\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 170, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=sample_weight, check_input=False)\n",
      "  File \"E:\\Anaconda\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"E:\\Anaconda\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  n_estimators=1200, min_samples_split=1, min_samples_leaf=4, max_features=sqrt, max_depth=90, bootstrap=False, total=   1.2s\n",
      "[CV] n_estimators=1200, min_samples_split=1, min_samples_leaf=4, max_features=sqrt, max_depth=90, bootstrap=False \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Anaconda\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\Anaconda\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"E:\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"E:\\Anaconda\\lib\\site-packages\\joblib\\parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"E:\\Anaconda\\lib\\site-packages\\joblib\\parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"E:\\Anaconda\\lib\\site-packages\\joblib\\parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"E:\\Anaconda\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"E:\\Anaconda\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"E:\\Anaconda\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"E:\\Anaconda\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"E:\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 170, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=sample_weight, check_input=False)\n",
      "  File \"E:\\Anaconda\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"E:\\Anaconda\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  n_estimators=1200, min_samples_split=1, min_samples_leaf=4, max_features=sqrt, max_depth=90, bootstrap=False, total=   0.7s\n",
      "[CV] n_estimators=1200, min_samples_split=1, min_samples_leaf=4, max_features=sqrt, max_depth=90, bootstrap=False \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Anaconda\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\Anaconda\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"E:\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"E:\\Anaconda\\lib\\site-packages\\joblib\\parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"E:\\Anaconda\\lib\\site-packages\\joblib\\parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"E:\\Anaconda\\lib\\site-packages\\joblib\\parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"E:\\Anaconda\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"E:\\Anaconda\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"E:\\Anaconda\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"E:\\Anaconda\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"E:\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 170, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=sample_weight, check_input=False)\n",
      "  File \"E:\\Anaconda\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"E:\\Anaconda\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  n_estimators=1200, min_samples_split=1, min_samples_leaf=4, max_features=sqrt, max_depth=90, bootstrap=False, total=   0.7s\n",
      "[CV] n_estimators=1800, min_samples_split=2, min_samples_leaf=6, max_features=auto, max_depth=20, bootstrap=True \n",
      "[CV]  n_estimators=1800, min_samples_split=2, min_samples_leaf=6, max_features=auto, max_depth=20, bootstrap=True, total=  47.5s\n",
      "[CV] n_estimators=1800, min_samples_split=2, min_samples_leaf=6, max_features=auto, max_depth=20, bootstrap=True \n",
      "[CV]  n_estimators=1800, min_samples_split=2, min_samples_leaf=6, max_features=auto, max_depth=20, bootstrap=True, total=  49.4s\n",
      "[CV] n_estimators=1800, min_samples_split=2, min_samples_leaf=6, max_features=auto, max_depth=20, bootstrap=True \n",
      "[CV]  n_estimators=1800, min_samples_split=2, min_samples_leaf=6, max_features=auto, max_depth=20, bootstrap=True, total=  41.7s\n",
      "[CV] n_estimators=800, min_samples_split=4, min_samples_leaf=6, max_features=auto, max_depth=80, bootstrap=False \n",
      "[CV]  n_estimators=800, min_samples_split=4, min_samples_leaf=6, max_features=auto, max_depth=80, bootstrap=False, total=  29.9s\n",
      "[CV] n_estimators=800, min_samples_split=4, min_samples_leaf=6, max_features=auto, max_depth=80, bootstrap=False \n",
      "[CV]  n_estimators=800, min_samples_split=4, min_samples_leaf=6, max_features=auto, max_depth=80, bootstrap=False, total=  30.4s\n",
      "[CV] n_estimators=800, min_samples_split=4, min_samples_leaf=6, max_features=auto, max_depth=80, bootstrap=False \n",
      "[CV]  n_estimators=800, min_samples_split=4, min_samples_leaf=6, max_features=auto, max_depth=80, bootstrap=False, total=  28.4s\n",
      "[CV] n_estimators=1800, min_samples_split=4, min_samples_leaf=2, max_features=sqrt, max_depth=50, bootstrap=False \n",
      "[CV]  n_estimators=1800, min_samples_split=4, min_samples_leaf=2, max_features=sqrt, max_depth=50, bootstrap=False, total= 1.1min\n",
      "[CV] n_estimators=1800, min_samples_split=4, min_samples_leaf=2, max_features=sqrt, max_depth=50, bootstrap=False \n",
      "[CV]  n_estimators=1800, min_samples_split=4, min_samples_leaf=2, max_features=sqrt, max_depth=50, bootstrap=False, total= 1.2min\n",
      "[CV] n_estimators=1800, min_samples_split=4, min_samples_leaf=2, max_features=sqrt, max_depth=50, bootstrap=False \n",
      "[CV]  n_estimators=1800, min_samples_split=4, min_samples_leaf=2, max_features=sqrt, max_depth=50, bootstrap=False, total=  58.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  30 out of  30 | elapsed: 15.6min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=3, estimator=RandomForestClassifier(),\n",
       "                   param_distributions={'bootstrap': [True, False],\n",
       "                                        'max_depth': [10, 20, 30, 40, 50, 60,\n",
       "                                                      70, 80, 90],\n",
       "                                        'max_features': ['auto', 'sqrt'],\n",
       "                                        'min_samples_leaf': [2, 4, 6],\n",
       "                                        'min_samples_split': [1, 2, 4],\n",
       "                                        'n_estimators': [200, 300, 400, 500,\n",
       "                                                         600, 700, 800, 900,\n",
       "                                                         1000, 1100, 1200, 1300,\n",
       "                                                         1400, 1500, 1600, 1700,\n",
       "                                                         1800, 1900]},\n",
       "                   random_state=42, verbose=2)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#使用随机搜索找到最佳模型\n",
    "#树的个数\n",
    "n_estimators = [int(x) for x in range(200, 2000, 100)]\n",
    "min_samples_leaf = [2, 4, 6]\n",
    "min_samples_split = [1, 2, 4]\n",
    "max_features = ['auto', 'sqrt']\n",
    "bootstrap = [True, False]\n",
    "max_depth = [int(x) for x in range(10, 100, 10)]\n",
    "param_random = {\n",
    "    'n_estimators': n_estimators,\n",
    "    'max_depth': max_depth,\n",
    "    'max_features': max_features,\n",
    "    'min_samples_leaf': min_samples_leaf,\n",
    "    'min_samples_split': min_samples_split,\n",
    "    'bootstrap': bootstrap\n",
    "}\n",
    "\n",
    "rf = RandomForestClassifier()\n",
    "rf_random = RandomizedSearchCV(estimator=rf, param_distributions=param_random, cv=3, verbose=2,\n",
    "                               random_state=42)\n",
    "rf_random.fit(x_train, y_train)\n",
    "# 获得最好的训练模型\n",
    "best_estimator = rf_random.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_forest = rf_random.best_estimator_\n",
    "#random_forest.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=False, max_depth=80, max_features='sqrt',\n",
       "                       min_samples_leaf=2, min_samples_split=4,\n",
       "                       n_estimators=1000)"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "重要性： [0.14218954 0.03725371 0.30026513 0.10379466 0.06007317 0.01408084\n",
      " 0.25784684 0.02314078 0.06135531]\n"
     ]
    }
   ],
   "source": [
    "importances = random_forest.feature_importances_\n",
    "print(\"重要性：\",importances)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "pd.Series(importances,index = x_train.columns).plot(kind = 'bar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = random_forest.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "cm1 = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "#展示混淆矩阵中的各项指标\n",
    "def show(cm):\n",
    "    TP = cm[1,1]\n",
    "    FN = cm[1,0]\n",
    "    FP = cm[0,1]\n",
    "    TN = cm[0,0]\n",
    "\n",
    "    accuracy = (TP/(TP+FN)+(TN/(TN+FP)))/2\n",
    "    P = TP/(TP+FP)\n",
    "    R = TP/(TP+FN)\n",
    "    F1 = 2/(1/P+1/R)\n",
    "\n",
    "    print(\"accracy:\",accuracy)\n",
    "    print(\"P:\",P)\n",
    "    print(\"R:\",R)\n",
    "    print(\"F1:\",F1)\n",
    "    return R"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[10893,    17],\n",
       "       [   23,   128]], dtype=int64)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accracy: 0.9230619578611274\n",
      "P: 0.8827586206896552\n",
      "R: 0.847682119205298\n",
      "F1: 0.8648648648648649\n"
     ]
    }
   ],
   "source": [
    "cm1\n",
    "show(cm1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import roc_curve,auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Anaconda\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10:40:13] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[10:40:14] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[10:40:15] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[10:40:15] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[10:40:16] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[10:40:17] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[10:40:18] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[10:40:18] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[10:40:19] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[10:40:20] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[10:40:20] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[10:40:21] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[10:40:22] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[10:40:22] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[10:40:23] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[10:40:24] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[10:40:24] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[10:40:25] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[10:40:26] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[10:40:27] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[10:40:28] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[10:40:28] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[10:40:29] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[10:40:30] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[10:40:31] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[10:40:31] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[10:40:33] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10:40:36] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[10:40:37] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[10:40:39] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[10:40:40] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[10:40:41] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[10:40:42] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[10:40:43] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[10:40:44] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[10:40:45] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[10:40:46] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[10:40:48] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[10:40:49] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[10:40:50] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[10:40:51] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[10:40:51] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[10:40:52] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[10:40:53] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[10:40:54] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[10:40:55] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[10:40:56] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[10:40:57] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[10:40:58] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[10:40:59] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[10:41:01] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[10:41:02] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[10:41:03] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[10:41:04] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10:41:05] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[10:41:06] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[10:41:07] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[10:41:08] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[10:41:09] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[10:41:10] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[10:41:11] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[10:41:12] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[10:41:13] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[10:41:14] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[10:41:16] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[10:41:17] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[10:41:18] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[10:41:19] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[10:41:20] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[10:41:21] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[10:41:22] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[10:41:23] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[10:41:25] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[10:41:26] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[10:41:27] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[10:41:28] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[10:41:30] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[10:41:31] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[10:41:32] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[10:41:33] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[10:41:35] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10:41:36] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[10:41:37] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[10:41:38] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[10:41:39] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[10:41:41] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[10:41:42] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[10:41:44] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[10:41:45] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[10:41:46] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[10:41:48] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[10:41:48] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[10:41:49] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[10:41:50] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[10:41:50] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[10:41:51] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[10:41:52] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[10:41:53] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[10:41:54] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[10:41:55] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[10:41:56] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[10:41:57] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[10:41:57] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[10:41:58] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[10:41:59] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[10:42:00] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[10:42:01] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[10:42:02] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10:42:03] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[10:42:04] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[10:42:05] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[10:42:06] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[10:42:07] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[10:42:08] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[10:42:09] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[10:42:10] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[10:42:11] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[10:42:12] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[10:42:14] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[10:42:15] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[10:42:16] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[10:42:17] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[10:42:17] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[10:42:18] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[10:42:19] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[10:42:20] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[10:42:21] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[10:42:22] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[10:42:23] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[10:42:24] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[10:42:25] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[10:42:26] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[10:42:28] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[10:42:29] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[10:42:30] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10:42:32] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[10:42:33] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[10:42:34] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[10:42:35] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[10:42:37] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[10:42:38] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[10:42:39] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[10:42:40] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[10:42:41] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[10:42:42] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[10:42:43] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[10:42:44] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[10:42:45] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[10:42:46] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[10:42:47] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[10:42:48] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[10:42:48] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[10:42:50] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[10:42:51] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[10:42:52] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[10:42:53] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[10:42:54] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[10:42:55] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[10:42:56] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[10:42:57] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[10:42:58] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[10:42:59] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10:43:00] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[10:43:01] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[10:43:02] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[10:43:05] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[10:43:07] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[10:43:10] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[10:43:13] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[10:43:15] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[10:43:17] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[10:43:19] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[10:43:21] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[10:43:22] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[10:43:23] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[10:43:25] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[10:43:26] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[10:43:27] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[10:43:29] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[10:43:30] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[10:43:31] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[10:43:32] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[10:43:32] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[10:43:33] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[10:43:34] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[10:43:34] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[10:43:35] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[10:43:36] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[10:43:36] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10:43:37] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[10:43:38] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[10:43:38] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[10:43:39] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[10:43:40] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[10:43:41] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[10:43:41] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[10:43:42] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[10:43:43] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[10:43:44] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[10:43:45] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[10:43:45] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[10:43:46] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[10:43:47] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[10:43:48] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[10:43:48] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[10:43:49] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[10:43:50] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[10:43:51] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[10:43:52] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[10:43:52] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[10:43:53] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[10:43:54] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[10:43:55] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[10:43:56] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[10:43:57] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[10:43:58] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10:44:00] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[10:44:01] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[10:44:02] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[10:44:03] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[10:44:04] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[10:44:05] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[10:44:06] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[10:44:07] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[10:44:08] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[10:44:09] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[10:44:10] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[10:44:11] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[10:44:12] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[10:44:13] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[10:44:14] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[10:44:15] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[10:44:16] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[10:44:17] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[10:44:18] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[10:44:20] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[10:44:21] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[10:44:22] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[10:44:23] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[10:44:24] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[10:44:25] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[10:44:26] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[10:44:27] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10:44:28] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[10:44:30] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[10:44:31] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[10:44:32] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[10:44:33] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[10:44:34] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[10:44:36] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[10:44:37] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[10:44:38] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[10:44:39] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[10:44:40] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[10:44:42] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[10:44:43] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[10:44:44] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[10:44:45] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[10:44:47] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[10:44:48] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[10:44:49] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[10:44:51] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[10:44:52] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[10:44:53] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[10:44:55] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[10:44:56] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[10:44:57] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[10:44:59] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[10:45:00] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[10:45:01] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10:45:03] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=3,\n",
       "             estimator=XGBClassifier(base_score=None, booster=None,\n",
       "                                     colsample_bylevel=None,\n",
       "                                     colsample_bynode=None,\n",
       "                                     colsample_bytree=None, gamma=None,\n",
       "                                     gpu_id=None, importance_type='gain',\n",
       "                                     interaction_constraints=None,\n",
       "                                     learning_rate=None, max_delta_step=None,\n",
       "                                     max_depth=None, min_child_weight=None,\n",
       "                                     missing=nan, monotone_constraints=None,\n",
       "                                     n_estimators=100, n_jobs=None,\n",
       "                                     num_parallel_tree=None, random_state=None,\n",
       "                                     reg_alpha=None, reg_lambda=None,\n",
       "                                     scale_pos_weight=None, subsample=None,\n",
       "                                     tree_method=None, validate_parameters=None,\n",
       "                                     verbosity=None),\n",
       "             param_grid={'colsample_bytree': array([0.5 , 0.75, 1.  ]),\n",
       "                         'n_estimators': range(80, 200, 4),\n",
       "                         'scale_pos_weight': [10]},\n",
       "             scoring='f1')"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf1 = xgb.XGBClassifier()\n",
    "param_dist = {\n",
    "        'n_estimators':range(80,200,4),    \n",
    "        'colsample_bytree':np.linspace(0.5,1,3),\n",
    "        'scale_pos_weight':[10]\n",
    "        }\n",
    "#使用网格搜索法找到最佳参数\n",
    "grid = GridSearchCV(clf1,param_dist,cv = 3,scoring = 'f1')\n",
    "\n",
    "grid.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
      "              colsample_bynode=1, colsample_bytree=0.75, gamma=0, gpu_id=-1,\n",
      "              importance_type='gain', interaction_constraints='',\n",
      "              learning_rate=0.300000012, max_delta_step=0, max_depth=6,\n",
      "              min_child_weight=1, missing=nan, monotone_constraints='()',\n",
      "              n_estimators=120, n_jobs=4, num_parallel_tree=1, random_state=0,\n",
      "              reg_alpha=0, reg_lambda=1, scale_pos_weight=10, subsample=1,\n",
      "              tree_method='exact', validate_parameters=1, verbosity=None)\n"
     ]
    }
   ],
   "source": [
    "XGB = grid.best_estimator_\n",
    "print(XGB)\n",
    "\n",
    "y_predict = XGB.predict(x_test)\n",
    "cm2 = confusion_matrix(y_test,y_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[10892,    18],\n",
       "       [   23,   128]], dtype=int64)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accracy: 0.9230161283469203\n",
      "P: 0.8767123287671232\n",
      "R: 0.847682119205298\n",
      "F1: 0.8619528619528619\n"
     ]
    }
   ],
   "source": [
    "cm2\n",
    "show(cm2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SVM\n",
    "from sklearn import svm\n",
    "clf = svm.SVC()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 14 candidates, totalling 70 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=8)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done  34 tasks      | elapsed:  1.8min\n",
      "[Parallel(n_jobs=8)]: Done  70 out of  70 | elapsed:  2.4min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(estimator=SVC(probability=True), n_jobs=8,\n",
       "             param_grid={'C': [0.001, 0.01, 0.1, 1, 10, 100, 1000],\n",
       "                         'gamma': [0.001, 0.0001]},\n",
       "             verbose=1)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = svm.SVC(kernel='rbf', probability=True)\n",
    "param_grid = {'C': [1e-3, 1e-2, 1e-1, 1, 10, 100, 1000], 'gamma': [0.001, 0.0001]}\n",
    "grid_search = GridSearchCV(model, param_grid, n_jobs = 8, verbose=1)\n",
    "grid_search.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVC(C=1000, gamma=0.001, probability=True)\n"
     ]
    }
   ],
   "source": [
    "svm = grid_search.best_estimator_\n",
    "print(svm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predict = svm.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[10900,    10],\n",
       "       [   41,   110]], dtype=int64)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accracy: 0.8637801154539549\n",
      "P: 0.9166666666666666\n",
      "R: 0.7284768211920529\n",
      "F1: 0.8118081180811807\n"
     ]
    }
   ],
   "source": [
    "cm3 = confusion_matrix(y_test,y_predict)\n",
    "cm3\n",
    "show(cm3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accracy: 0.866587249075822\n",
      "P: 0.8409090909090909\n",
      "R: 0.7350993377483444\n",
      "F1: 0.7844522968197879\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "lr_model = LogisticRegression() #调用逻辑回归模型\n",
    "lr_model.fit(x_train,y_train)\n",
    "y_predict = lr_model.predict(x_test)\n",
    "cm4 = confusion_matrix(y_test,y_predict)\n",
    "show(cm4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[10889,    21],\n",
       "       [   40,   111]], dtype=int64)"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accracy: 0.866587249075822\n",
      "P: 0.8409090909090909\n",
      "R: 0.7350993377483444\n",
      "F1: 0.7844522968197879\n"
     ]
    }
   ],
   "source": [
    "cm4\n",
    "show(cm4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MLPClassifier(hidden_layer_sizes=5)"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accracy: 0.8370150721435465\n",
      "P: 0.864406779661017\n",
      "R: 0.6754966887417219\n",
      "F1: 0.758364312267658\n",
      "accracy: 0.8370150721435465\n",
      "P: 0.864406779661017\n",
      "R: 0.6754966887417219\n",
      "F1: 0.758364312267658\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLPClassifier(hidden_layer_sizes=20)"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accracy: 0.876475194396052\n",
      "P: 0.8382352941176471\n",
      "R: 0.7549668874172185\n",
      "F1: 0.794425087108014\n",
      "accracy: 0.876475194396052\n",
      "P: 0.8382352941176471\n",
      "R: 0.7549668874172185\n",
      "F1: 0.794425087108014\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLPClassifier(hidden_layer_sizes=50)"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accracy: 0.8733930836889421\n",
      "P: 0.8692307692307693\n",
      "R: 0.7483443708609272\n",
      "F1: 0.804270462633452\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLPClassifier(hidden_layer_sizes=100)"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accracy: 0.9086253573791587\n",
      "P: 0.7425149700598802\n",
      "R: 0.8211920529801324\n",
      "F1: 0.779874213836478\n",
      "accracy: 0.9086253573791587\n",
      "P: 0.7425149700598802\n",
      "R: 0.8211920529801324\n",
      "F1: 0.779874213836478\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLPClassifier(hidden_layer_sizes=200)"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accracy: 0.8701276549250034\n",
      "P: 0.875\n",
      "R: 0.7417218543046358\n",
      "F1: 0.8028673835125448\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLPClassifier(hidden_layer_sizes=1000)"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accracy: 0.8670455442178935\n",
      "P: 0.9098360655737705\n",
      "R: 0.7350993377483444\n",
      "F1: 0.8131868131868131\n"
     ]
    }
   ],
   "source": [
    "#Neural Network\n",
    "from sklearn import neural_network\n",
    "R = 0\n",
    "\n",
    "for i in [5,20,50,100,200,1000]:\n",
    "    mlp=neural_network.MLPClassifier(hidden_layer_sizes=(i), #隐藏层\n",
    "                                     #（10,20）指的是隐藏层层数+每层单元数\n",
    "                                    activation='relu',  #激活函数\n",
    "                                    solver='adam',\n",
    "                                    alpha=0.0001,  #正则化项系数\n",
    "                                    batch_size='auto',\n",
    "                                    learning_rate='constant',  #学习率\n",
    "                                    learning_rate_init=0.001,\n",
    "                                    power_t=0.5,\n",
    "                                    max_iter=200,  #迭代次数\n",
    "                                    tol=1e-4)\n",
    "    mlp.fit(x_train,y_train)\n",
    "    y_predict = mlp.predict(x_test)\n",
    "    cm5 = confusion_matrix(y_test,y_predict)\n",
    "    if show(cm5)>R:\n",
    "        R = show(cm5)\n",
    "        best_estimator = mlp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[10899,    11],\n",
       "       [   40,   111]], dtype=int64)"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cm5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[10867,    43],\n",
       "       [   27,   124]], dtype=int64)"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accracy: 0.9086253573791587\n",
      "P: 0.7425149700598802\n",
      "R: 0.8211920529801324\n",
      "F1: 0.779874213836478\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8211920529801324"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#mlp.fit(x_train,y_train)\n",
    "y_predict = best_estimator.predict(x_test)\n",
    "cm5 = confusion_matrix(y_test,y_predict)\n",
    "cm5\n",
    "show(cm5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "import textdistance\n",
    "def clean_string(str1):\n",
    "    str1 = str1.lower()\n",
    "    str1 =str1.replace('mr.','')\n",
    "    str1 =str1.replace('mrs.','')\n",
    "    str1 =str1.replace('\\n',' \\n')\n",
    "    str1 =str1.replace('\\n',' \\n')\n",
    "    str1 =str1.replace('\\n',' \\n')\n",
    "    str1 =str1.replace('.',' ')\n",
    "    str1 =str1.replace(',',' ')\n",
    "    str1 =str1.replace('\\'','')\n",
    "    str1 =str1.replace(' & ',' and ')\n",
    "    str1 =str1.replace(' &',' and ')\n",
    "    str1 =str1.replace('& ',' and ')\n",
    "    str1 =str1.replace('&',' and ')\n",
    "    str1 =str1.replace(' l p ',' lp ')\n",
    "    str1 =str1.replace('l l p ','llp ')\n",
    "    str1 =str1.replace('l l c ','llc ')\n",
    "    str1 =str1.replace(' ltd ',' limited ')\n",
    "    str1 =str1.replace(' p l c ',' plc')\n",
    "    str1 =str1.replace(' co ltd ',' company limited ')\n",
    "    str1 =str1.replace(' co ',' company ')\n",
    "    str1 =str1.replace(' corp ',' corporation ')\n",
    "    str1 =str1.replace(' univ ',' university ')\n",
    "    str1 =str1.replace(' fdtn ',' foundation ')\n",
    "    str1 =str1.replace(' inc ',' incorporated ')\n",
    "    str1 =str1.replace(' assoc ',' association ')\n",
    "    str1 =str1.replace(' mgmt ',' management ')\n",
    "    str1 =str1.replace(' svsc ',' services ')\n",
    "    str1 =str1.replace(' ag ',' aktiengesellschaft ')\n",
    "    str1 =str1.replace(' govt ',' goverment ')\n",
    "    str1 =str1.replace(' svgs ',' savings ')\n",
    "    str1 =str1.replace(' intl ',' international ')\n",
    "    str1 =str1.replace('intl ','international ')\n",
    "    str1 =str1.replace(' investmentco lt ',' investment company limited ')\n",
    "    str1 = str1.replace('the ','')\n",
    "    str1 = str1.replace(' the ','')\n",
    "    str1 = str1.strip()\n",
    "    return str1\n",
    "\n",
    "def InstringSerch(a,b):\n",
    "    return int(a in b or b in a)\n",
    "\n",
    "\n",
    "def get_similarity(a,b):\n",
    "    a = clean_string(a)\n",
    "    b = clean_string(b)\n",
    "    Cosine_Similarity = textdistance.cosine.similarity(a,b)\n",
    "    Levenshtein_Distance = textdistance.levenshtein.distance(a,b)\n",
    "    Jaro_Winkler_Distance = textdistance.jaro_winkler.similarity(a,b)\n",
    "    Jaccard_Index = textdistance.jaccard.similarity(a,b)\n",
    "    Monge_Elkan = textdistance.monge_elkan.similarity(a,b)\n",
    "    MRA = textdistance.mra.similarity(a,b)\n",
    "    Longest_Common_Substring = textdistance.lcsstr.similarity(a,b)\n",
    "    Longest_Common_ubsequence = textdistance.lcsseq.similarity(a,b)\n",
    "    In_String_Search = InStringSerch(a,b)\n",
    "    return pd.DataFrame({'Cosine Similarity':Cosine_Similarity,'Levenshtein Distance':Levenshtein_Distance,\n",
    "            'Jaro-Winkler Distance':Jaro_Winkler_Distance,'Jaccard Index':Jaccard_Index,'Monge Elkan':Monge_Elkan,\n",
    "            'MRA':MRA,'Longest Common Substring':Longest_Common_Substring,\n",
    "            'Longest Common Subsequence':Longest_Common_ubsequence,'In String Search':In_String_Search},index = [0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = 'avs'\n",
    "b = 'acs sdw'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Cosine Similarity</th>\n",
       "      <th>Levenshtein Distance</th>\n",
       "      <th>Jaro-Winkler Distance</th>\n",
       "      <th>Jaccard Index</th>\n",
       "      <th>Monge Elkan</th>\n",
       "      <th>MRA</th>\n",
       "      <th>Longest Common Substring</th>\n",
       "      <th>Longest Common Subsequence</th>\n",
       "      <th>In String Search</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.436436</td>\n",
       "      <td>5</td>\n",
       "      <td>0.650794</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Cosine Similarity  Levenshtein Distance  Jaro-Winkler Distance  \\\n",
       "0           0.436436                     5               0.650794   \n",
       "\n",
       "   Jaccard Index  Monge Elkan  MRA  Longest Common Substring  \\\n",
       "0           0.25     0.222222    0                         1   \n",
       "\n",
       "   Longest Common Subsequence  In String Search  \n",
       "0                           2                 0  "
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_similarity(a,b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "请输入第一个字符串:AMILIAWONG\n",
      "请输入第二个字符串:AMELIA WONG\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Cosine Similarity</th>\n",
       "      <th>Levenshtein Distance</th>\n",
       "      <th>Jaro-Winkler Distance</th>\n",
       "      <th>Jaccard Index</th>\n",
       "      <th>Monge Elkan</th>\n",
       "      <th>MRA</th>\n",
       "      <th>Longest Common Substring</th>\n",
       "      <th>Longest Common Subsequence</th>\n",
       "      <th>In String Search</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.858116</td>\n",
       "      <td>2</td>\n",
       "      <td>0.895219</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.1</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Cosine Similarity  Levenshtein Distance  Jaro-Winkler Distance  \\\n",
       "0           0.858116                     2               0.895219   \n",
       "\n",
       "   Jaccard Index  Monge Elkan  MRA  Longest Common Substring  \\\n",
       "0           0.75          0.1    6                         4   \n",
       "\n",
       "   Longest Common Subsequence  In String Search  \n",
       "0                           9                 0  "
      ]
     },
     "execution_count": 217,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "您输入的字符串分别为：AMILIAWONG , AMELIA WONG\n",
      "Match\n"
     ]
    }
   ],
   "source": [
    "a = input(\"请输入第一个字符串:\")\n",
    "b = input(\"请输入第二个字符串:\")\n",
    "get_similarity(a,b)\n",
    "print('您输入的字符串分别为：'+str(a)+' , '+str(b))\n",
    "print(['Match' if random_forest.predict(get_similarity(a,b))[0]==1 else 'Not Match'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get(cm):\n",
    "    TP = cm[1,1]\n",
    "    FN = cm[1,0]\n",
    "    FP = cm[0,1]\n",
    "    TN = cm[0,0]\n",
    "\n",
    "    accuracy = (TP/(TP+FN)+(TN/(TN+FP)))/2\n",
    "    P = TP/(TP+FP)\n",
    "    R = TP/(TP+FN)\n",
    "    F1 = 2/(1/P+1/R)\n",
    "\n",
    "    return [accuracy,P,R,F1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm_list = [cm1,cm2,cm3,cm4,cm5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "dic = {}\n",
    "dic['accuracy'] = [get(i)[0] for i in cm_list]\n",
    "dic['P'] = [get(i)[1] for i in cm_list]\n",
    "dic['R'] = [get(i)[2] for i in cm_list]\n",
    "dic['F1'] = [get(i)[3] for i in cm_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accuracy</th>\n",
       "      <th>P</th>\n",
       "      <th>R</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>random_forest</th>\n",
       "      <td>0.923062</td>\n",
       "      <td>0.882759</td>\n",
       "      <td>0.847682</td>\n",
       "      <td>0.864865</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>xgboost</th>\n",
       "      <td>0.923016</td>\n",
       "      <td>0.876712</td>\n",
       "      <td>0.847682</td>\n",
       "      <td>0.861953</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>svm</th>\n",
       "      <td>0.863780</td>\n",
       "      <td>0.916667</td>\n",
       "      <td>0.728477</td>\n",
       "      <td>0.811808</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>logistic_regression</th>\n",
       "      <td>0.866587</td>\n",
       "      <td>0.840909</td>\n",
       "      <td>0.735099</td>\n",
       "      <td>0.784452</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Neural Network</th>\n",
       "      <td>0.908625</td>\n",
       "      <td>0.742515</td>\n",
       "      <td>0.821192</td>\n",
       "      <td>0.779874</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     accuracy         P         R        F1\n",
       "random_forest        0.923062  0.882759  0.847682  0.864865\n",
       "xgboost              0.923016  0.876712  0.847682  0.861953\n",
       "svm                  0.863780  0.916667  0.728477  0.811808\n",
       "logistic_regression  0.866587  0.840909  0.735099  0.784452\n",
       "Neural Network       0.908625  0.742515  0.821192  0.779874"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(dic,index = ['random_forest','xgboost','svm','logistic_regression','Neural Network'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
